{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02f0b5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rapidfuzz in d:\\python\\lib\\site-packages (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install rapidfuzz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14084a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from fuzzywuzzy import fuzz, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f48864e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read datasets\n",
    "left_dataset = pd.read_csv(\"/Users/andychen/Desktop/Columbia_U/CU_2023_Spring/APAN5210/left_dataset.csv\")\n",
    "right_dataset = pd.read_csv(\"/Users/andychen/Desktop/Columbia_U/CU_2023_Spring/APAN5210/right_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46d96c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 98509 entries, 0 to 98508\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   business_id  98509 non-null  int64  \n",
      " 1   name         98509 non-null  object \n",
      " 2   address      98509 non-null  object \n",
      " 3   city         98509 non-null  object \n",
      " 4   state        98509 non-null  object \n",
      " 5   zip_code     98509 non-null  object \n",
      " 6   size         98509 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 5.3+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94585 entries, 0 to 94584\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   entity_id    94585 non-null  int64  \n",
      " 1   name         94585 non-null  object \n",
      " 2   address      91787 non-null  object \n",
      " 3   city         94585 non-null  object \n",
      " 4   state        94585 non-null  object \n",
      " 5   postal_code  94548 non-null  float64\n",
      " 6   categories   94523 non-null  object \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 5.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# check information of both datasets\n",
    "print(left_dataset.info())\n",
    "print(right_dataset.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd443d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values in left_dataset：\n",
      " business_id    0\n",
      "name           0\n",
      "address        0\n",
      "city           0\n",
      "state          0\n",
      "zip_code       0\n",
      "size           0\n",
      "dtype: int64\n",
      "missing values in right_dataset：\n",
      " entity_id         0\n",
      "name              0\n",
      "address        2798\n",
      "city              0\n",
      "state             0\n",
      "postal_code      37\n",
      "categories       62\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check missing values of left_dataset \n",
    "left_missing_values = left_dataset.isna().sum()\n",
    "print(\"missing values in left_dataset：\\n\", left_missing_values)\n",
    "\n",
    "#check missing values of right_dataset \n",
    "right_missing_values = right_dataset.isna().sum()\n",
    "print(\"missing values in right_dataset：\\n\", right_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47bbdb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop na values of 'address' column in right dataset\n",
    "right_dataset = right_dataset.dropna(subset=['address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8c3db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remane 'postal_code' in right_dataset to 'zip_code' and fill na with 0\n",
    "right_dataset = right_dataset.rename(columns={\"postal_code\": \"zip_code\"})\n",
    "right_dataset['zip_code'] = right_dataset['zip_code'].fillna(0).astype(int)\n",
    "right_dataset[\"zip_code\"] = right_dataset[\"zip_code\"].astype(str).str.split(\".\").str[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5e2ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process 'zip_code' in left_dataset and change its type to integer\n",
    "left_dataset[\"zip_code\"] = left_dataset[\"zip_code\"].str.split(\"-\").str[0]\n",
    "left_dataset[\"zip_code\"] = left_dataset[\"zip_code\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b366048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned the symbols and blank spaces in 'city' column, then make all letters in 'name' and 'city' lowercase\n",
    "for col in [\"city\"]:\n",
    "    left_dataset[col] = left_dataset[col].str.lower().str.replace(r'\\W+', '', regex=True)\n",
    "    right_dataset[col] = right_dataset[col].str.lower().str.replace(r'\\W+', '', regex=True)\n",
    "\n",
    "left_dataset[\"name\"] = left_dataset[\"name\"].str.lower()\n",
    "right_dataset[\"name\"] = right_dataset[\"name\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c93cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort values of right dataset in the order of state, city, and zip_code\n",
    "right_dataset = right_dataset.sort_values([\"state\", \"city\",\"zip_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10bb6610",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set index of right dataset to enhance the matching efficiency\n",
    "right_indexed = right_dataset.set_index([\"state\", \"city\",\"zip_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e7f0508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set threshold\n",
    "threshold = 80\n",
    "\n",
    "results = []\n",
    "\n",
    "for index_left, row_left in left_dataset.iterrows():\n",
    "    #filter right_dataset subsets with the same state, city, and zip_code\n",
    "    state_city_zip = (row_left[\"state\"], row_left[\"city\"], row_left[\"zip_code\"])\n",
    "    \n",
    "    try:\n",
    "        right_subset = right_indexed.loc[state_city_zip]\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "    if not right_subset.empty:\n",
    "        #use process.extractOne to quickly find the best address match\n",
    "        best_address_match_data = process.extractOne(row_left[\"address\"], right_subset[\"address\"], scorer=fuzz.token_sort_ratio)\n",
    "        best_address_match = best_address_match_data[0]\n",
    "        best_address_score = best_address_match_data[1]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #use process.extractOne to quickly find the best name match\n",
    "        best_name_match_data = process.extractOne(row_left[\"name\"], right_subset[\"name\"], scorer=fuzz.token_sort_ratio)\n",
    "        best_name_match = best_name_match_data[0]\n",
    "        best_name_score = best_name_match_data[1]\n",
    "\n",
    "\n",
    "        #calculate the combined score\n",
    "        combined_score = (best_name_score + best_address_score) / 2\n",
    "\n",
    "        #check if the match score is above the threshold\n",
    "        if combined_score >= threshold:\n",
    "            #Process the match here and add it to the result list\n",
    "            match_id_left = row_left[\"business_id\"]\n",
    "            match_id_right = right_subset[right_subset[\"address\"] == best_address_match].iloc[0][\"entity_id\"]\n",
    "            results.append((match_id_left, match_id_right, combined_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3019bbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the result into DataFrame\n",
    "results_df = pd.DataFrame(results, columns=[\"left_business_id\", \"right_business_id\", \"confidence_score\"])\n",
    "\n",
    "\n",
    "\n",
    "#save the result in csv file\n",
    "results_df.to_csv(\"E:/matched_businesses01.csv\", index=False)\n",
    "\n",
    "print(\"matched business and confidence score is saved in matched_businesses01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a413ccd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
